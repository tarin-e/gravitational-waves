{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# critical\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "\n",
    "# deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# signal processing\n",
    "from scipy import signal\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  99\n"
     ]
    }
   ],
   "source": [
    "# set random seed for reproducibility\n",
    "manualSeed = 99\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "\n",
    "np.random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "torch.use_deterministic_algorithms(True) # Needed for reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")\n",
    "\n",
    "# number of channels the signal has\n",
    "nc = 1\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from dataloader todo: get statistics straight from the dataset / dataloader object\n",
    "dataset_mean = -0.50727963\n",
    "dataset_std = 35.344276\n",
    "scaling_factor = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.main = nn.Sequential(\n",
    "                nn.ConvTranspose1d(nz, ngf * 32, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "                nn.BatchNorm1d(ngf * 32),\n",
    "                nn.LeakyReLU(True),\n",
    "\n",
    "                nn.ConvTranspose1d(ngf * 32, ngf * 16, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "                nn.BatchNorm1d(ngf * 16),\n",
    "                nn.LeakyReLU(True),\n",
    "\n",
    "                nn.ConvTranspose1d(ngf * 16, ngf * 8, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "                nn.BatchNorm1d(ngf * 8),\n",
    "                nn.LeakyReLU(True),\n",
    "\n",
    "                nn.ConvTranspose1d(ngf * 8, ngf * 4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "                nn.BatchNorm1d(ngf * 4),\n",
    "                nn.LeakyReLU(True),\n",
    "\n",
    "                nn.ConvTranspose1d(ngf * 4, ngf * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "                nn.BatchNorm1d(ngf * 2),\n",
    "                nn.LeakyReLU(True),\n",
    "\n",
    "                nn.ConvTranspose1d(ngf * 2, ngf, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "                nn.BatchNorm1d(ngf),\n",
    "                nn.LeakyReLU(True),\n",
    "\n",
    "                nn.ConvTranspose1d(ngf, nc, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            )\n",
    "\n",
    "        def forward(self, z):\n",
    "            z = self.main(z)\n",
    "            return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Generate Signals from Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (main): Sequential(\n",
       "    (0): ConvTranspose1d(100, 2048, kernel_size=(4,), stride=(1,), bias=False)\n",
       "    (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=True)\n",
       "    (3): ConvTranspose1d(2048, 1024, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
       "    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=True)\n",
       "    (6): ConvTranspose1d(1024, 512, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
       "    (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=True)\n",
       "    (9): ConvTranspose1d(512, 256, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
       "    (10): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): LeakyReLU(negative_slope=True)\n",
       "    (12): ConvTranspose1d(256, 128, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
       "    (13): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): LeakyReLU(negative_slope=True)\n",
       "    (15): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
       "    (16): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): LeakyReLU(negative_slope=True)\n",
       "    (18): ConvTranspose1d(64, 1, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_generator = torch.load(\"../models/stellar_core_collapse_signal_generator_dcgans.pt\").to(device)\n",
    "signal_generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_signals = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Generator 100 times and report statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 4.7275550365448 seconds\n",
      "Execution Time: 4.7183239459991455 seconds\n",
      "Execution Time: 4.726958990097046 seconds\n",
      "Execution Time: 4.753612041473389 seconds\n",
      "Execution Time: 4.708114862442017 seconds\n",
      "Execution Time: 4.692321062088013 seconds\n",
      "Execution Time: 4.70231032371521 seconds\n",
      "Execution Time: 4.692811012268066 seconds\n",
      "Execution Time: 4.702416896820068 seconds\n",
      "Execution Time: 4.68743109703064 seconds\n",
      "Execution Time: 4.698410987854004 seconds\n",
      "Execution Time: 4.699047088623047 seconds\n",
      "Execution Time: 4.68675684928894 seconds\n",
      "Execution Time: 4.696173906326294 seconds\n",
      "Execution Time: 4.702950954437256 seconds\n",
      "Execution Time: 4.702214002609253 seconds\n",
      "Execution Time: 4.7049720287323 seconds\n",
      "Execution Time: 4.69832181930542 seconds\n",
      "Execution Time: 4.717931032180786 seconds\n",
      "Execution Time: 4.704822063446045 seconds\n",
      "Execution Time: 4.699954032897949 seconds\n",
      "Execution Time: 4.700416088104248 seconds\n",
      "Execution Time: 4.7084596157073975 seconds\n",
      "Execution Time: 4.708629846572876 seconds\n",
      "Execution Time: 4.7852771282196045 seconds\n",
      "Execution Time: 4.600064992904663 seconds\n",
      "Execution Time: 4.627774000167847 seconds\n",
      "Execution Time: 4.668166875839233 seconds\n",
      "Execution Time: 4.590733766555786 seconds\n",
      "Execution Time: 4.592318058013916 seconds\n",
      "Execution Time: 4.615987062454224 seconds\n",
      "Execution Time: 4.618244171142578 seconds\n",
      "Execution Time: 4.622468709945679 seconds\n",
      "Execution Time: 4.61765193939209 seconds\n",
      "Execution Time: 4.61853814125061 seconds\n",
      "Execution Time: 4.632524728775024 seconds\n",
      "Execution Time: 4.617635011672974 seconds\n",
      "Execution Time: 4.608789920806885 seconds\n",
      "Execution Time: 4.628528833389282 seconds\n",
      "Execution Time: 4.604537725448608 seconds\n",
      "Execution Time: 4.615481853485107 seconds\n",
      "Execution Time: 4.602855205535889 seconds\n",
      "Execution Time: 4.608740329742432 seconds\n",
      "Execution Time: 4.624969005584717 seconds\n",
      "Execution Time: 4.593580007553101 seconds\n",
      "Execution Time: 4.624650955200195 seconds\n",
      "Execution Time: 4.605690240859985 seconds\n",
      "Execution Time: 4.599996089935303 seconds\n",
      "Execution Time: 4.591659069061279 seconds\n",
      "Execution Time: 4.597323894500732 seconds\n",
      "Execution Time: 4.591651201248169 seconds\n",
      "Execution Time: 4.591773986816406 seconds\n",
      "Execution Time: 4.593174934387207 seconds\n",
      "Execution Time: 4.594372987747192 seconds\n",
      "Execution Time: 4.592721223831177 seconds\n",
      "Execution Time: 4.5927722454071045 seconds\n",
      "Execution Time: 4.5929646492004395 seconds\n",
      "Execution Time: 4.592923879623413 seconds\n",
      "Execution Time: 4.631978988647461 seconds\n",
      "Execution Time: 4.717663764953613 seconds\n",
      "Execution Time: 4.712383031845093 seconds\n",
      "Execution Time: 4.754180908203125 seconds\n",
      "Execution Time: 4.698098182678223 seconds\n",
      "Execution Time: 4.588534116744995 seconds\n",
      "Execution Time: 4.587039947509766 seconds\n",
      "Execution Time: 4.5886757373809814 seconds\n",
      "Execution Time: 4.590076208114624 seconds\n",
      "Execution Time: 4.597275018692017 seconds\n",
      "Execution Time: 4.644208192825317 seconds\n",
      "Execution Time: 4.6404430866241455 seconds\n",
      "Execution Time: 4.6008899211883545 seconds\n",
      "Execution Time: 4.591953277587891 seconds\n",
      "Execution Time: 4.597916841506958 seconds\n",
      "Execution Time: 4.619071960449219 seconds\n",
      "Execution Time: 4.638141870498657 seconds\n",
      "Execution Time: 4.598201036453247 seconds\n",
      "Execution Time: 4.590804100036621 seconds\n",
      "Execution Time: 4.589114189147949 seconds\n",
      "Execution Time: 4.586929082870483 seconds\n",
      "Execution Time: 4.58681321144104 seconds\n",
      "Execution Time: 4.5864577293396 seconds\n",
      "Execution Time: 4.586603879928589 seconds\n",
      "Execution Time: 4.586684942245483 seconds\n",
      "Execution Time: 4.586838722229004 seconds\n",
      "Execution Time: 4.586944818496704 seconds\n",
      "Execution Time: 4.586683988571167 seconds\n",
      "Execution Time: 4.587050914764404 seconds\n",
      "Execution Time: 4.586426019668579 seconds\n",
      "Execution Time: 4.586942911148071 seconds\n",
      "Execution Time: 4.5904459953308105 seconds\n",
      "Execution Time: 4.593150854110718 seconds\n",
      "Execution Time: 4.589379072189331 seconds\n",
      "Execution Time: 4.587368011474609 seconds\n",
      "Execution Time: 4.585946083068848 seconds\n",
      "Execution Time: 4.586802959442139 seconds\n",
      "Execution Time: 4.589658975601196 seconds\n",
      "Execution Time: 4.586916208267212 seconds\n",
      "Execution Time: 4.586983919143677 seconds\n",
      "Execution Time: 4.586709022521973 seconds\n",
      "Execution Time: 4.589668035507202 seconds\n",
      "Execution Time Mean: 4.633015141487122 seconds,  Execution Time Std: 0.05306113870903299 seconds\n"
     ]
    }
   ],
   "source": [
    "execution_times = np.array([])\n",
    "\n",
    "# generate fake signals, record computing time\n",
    "for i in range(100):\n",
    "    # generate random noise latent vectors\n",
    "    fixed_noise = torch.randn(number_of_signals, nz, 1, device=device)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        generated_signals = signal_generator(fixed_noise).detach().cpu()\n",
    "    end_time = time.time()\n",
    "\n",
    "    execution_time = end_time - start_time\n",
    "    execution_times = np.append(execution_times, execution_time)\n",
    "    print(\"Execution Time:\", execution_time, \"seconds\")\n",
    "\n",
    "execution_time_mean = np.mean(execution_times)\n",
    "execution_time_std = np.std(execution_times)\n",
    "\n",
    "print(\"Execution Time Mean:\", execution_time_mean, \"seconds, \", \"Execution Time Std:\", execution_time_std, \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
